{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener la ruta de la carpeta actual y subir una carpeta\n",
    "parent_directory = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Ruta de descarga personalizada\n",
    "Data_path = os.path.join(parent_directory, \"Data\")\n",
    "productos_path = os.path.join(Data_path, \"productos_prueba_v2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joa\\AppData\\Local\\Temp\\ipykernel_25384\\562491179.py:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_tickets = pd.read_csv(tickets_path, sep=';', encoding='utf-8', index_col=None)\n"
     ]
    }
   ],
   "source": [
    "tickets_path = os.path.join(Data_path, \"tickets_prueba_v2.txt\")\n",
    "df_tickets = pd.read_csv(tickets_path, sep=';', encoding='utf-8', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(productos_path, 'r', encoding='utf-8',errors=\"replace\") as file:\n",
    "    content = file.read()\n",
    "# Eliminar todas las apariciones de '_x000D_'\n",
    "content = content.replace('_x000D_', '')\n",
    "# Reemplazar 'RF.I;' por 'RF.I:'\n",
    "content = content.replace('RF.I;', 'RF.I:')\n",
    "\n",
    "# Crear archivo temporal para los datos procesados\n",
    "with tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8') as temp_file:\n",
    "    temp_file.write(content)\n",
    "    temp_file_path = temp_file.name  # Obtener la ruta del archivo temporal\n",
    "\n",
    "# Procesar las líneas del archivo temporal\n",
    "with open(temp_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "new_lines = []\n",
    "buffer_line = \"\"\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "\n",
    "    # Si la línea empieza con un número, es una nueva línea de datos\n",
    "    if re.match(r\"^\\d+\", line):\n",
    "        if buffer_line:\n",
    "            new_lines.append(buffer_line)  # Guardamos la línea acumulada\n",
    "        buffer_line = line  # Iniciar una nueva línea\n",
    "    else:\n",
    "        buffer_line += \" \" + line  # Concatenamos con la anterior\n",
    "\n",
    "# Agregar la última línea acumulada si existe\n",
    "if buffer_line:\n",
    "    new_lines.append(buffer_line)\n",
    "\n",
    "# Guardar el contenido corregido en el archivo temporal\n",
    "with open(temp_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(new_lines))\n",
    "# Flag para verificar si hubo cambios en las líneas\n",
    "changes_made = True\n",
    "while changes_made:    \n",
    "    changes_made = False\n",
    "    # Procesar las líneas del archivo temporal\n",
    "    with open(temp_file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    new_lines = []\n",
    "    new_lines.append(lines[0])\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split(';')\n",
    "\n",
    "        if len(parts) >= 4 and not parts[3].isdigit():\n",
    "            parts[2] = parts[2] + ' ' + parts[3]\n",
    "            parts = parts[:3] + parts[4:]\n",
    "\n",
    "            # Si hubo un cambio, marcamos la bandera como True\n",
    "            changes_made = True\n",
    "\n",
    "\n",
    "        new_line = ';'.join(parts)\n",
    "        new_lines.append(new_line)\n",
    "\n",
    "    # Guardar el contenido corregido en el archivo temporal\n",
    "    with open(temp_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n'.join(new_lines))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo procesado con pandas\n",
    "df = pd.read_csv(temp_file_path, sep=';', encoding='utf-8')\n",
    "\n",
    "df.columns = df.columns.str.strip()  # Elimina espacios al inicio y al final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tabla Sectores (eliminar sector con valor 0)\n",
    "df_sectores = df[['id_sector', 'sector','idcadena']].drop_duplicates().reset_index(drop=True)\n",
    "df_sectores = df_sectores[df_sectores['sector'] != 'SECTOR_PRUEBA']\n",
    "\n",
    "# 2. Tabla Secciones (eliminar secciones con id 0 y 1)\n",
    "df_secciones = df[['id_seccion', 'seccion','idcadena']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 3. Tabla Categorias (eliminar categoria con id 1)\n",
    "df_categorias = df[['id_categoria', 'categoria','idcadena']].drop_duplicates().reset_index(drop=True)\n",
    "df_categorias = df_categorias[df_categorias['categoria'] != 'CATEGORIA_PRUEBA']\n",
    "\n",
    "# 4. Tabla Subcategorias (eliminar subcategoria con id 1)\n",
    "df_subcategorias = df[['id_subcategoria', 'subcategoria','idcadena']].drop_duplicates().reset_index(drop=True)\n",
    "df_subcategorias = df_subcategorias[df_subcategorias['subcategoria'] != 'SUBCAPRUEBA']\n",
    "\n",
    "# 8. Tabla Productos (principal)\n",
    "df_productos = df[['idcadena','eancode', 'descripcion', 'id_sector', 'id_seccion', 'id_categoria', 'id_subcategoria', \n",
    "                   'fabricante', 'marca', 'contenido', 'pesovolumen', 'unidadmedida', 'ultmodificacion', 'id','granfamilia', 'familia']]\n",
    "\n",
    "\n",
    "# Eliminar las filas donde id_seccion sea 61\n",
    "df_productos = df_productos[df_productos['id_seccion'] != 61]\n",
    "df_productos = df_productos.drop_duplicates(subset=['id_sector', 'id_seccion', 'eancode', 'id_categoria', 'fabricante'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar las variables de entorno desde .env\n",
    "load_dotenv()\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")  # Puedes agregar esto al .env si prefieres\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = \"spaceman\"\n",
    "\n",
    "# Crear la URL de conexión a PostgreSQL\n",
    "database_url = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "# Crear una conexión a la base de datos usando SQLAlchemy\n",
    "engine = create_engine(database_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_categorias.to_sql('categorias', con=engine, schema='maestros', if_exists='append', index=False)\n",
    "\n",
    "\n",
    "df_sectores.to_sql('sectores', con=engine, schema='maestros', if_exists='append', index=False)\n",
    "\n",
    "df_secciones.to_sql('secciones', con=engine, schema='maestros', if_exists='append', index=False)\n",
    "\n",
    "df_subcategorias.to_sql('subcategorias', con=engine, schema='maestros', if_exists='append', index=False)\n",
    "\n",
    "df_productos.to_sql('productos', con=engine, schema='maestros', if_exists='append', index=False)\n",
    "\n",
    "df_tickets.to_sql('tickets', con=engine, schema='maestros', if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_spaceman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
